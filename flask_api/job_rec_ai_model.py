# -*- coding: utf-8 -*-
"""[Final]Job_Rec_AI_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wfxrkiKDc-U5MTweJQDRyY9TNCEE0kBI
"""

import pandas as pd  # To handle data like a table
from sklearn.feature_extraction.text import TfidfVectorizer  # To handle job descriptions and skills
from sklearn.metrics.pairwise import cosine_similarity  # To find similar jobs
import numpy as np

jobs_df=pd.read_csv('/content/data_sample_for_naukri_com-jobs__20190701_20190830__30k_data.csv')
jobs_df.head()

# Drop rows with missing values
jobs_df = jobs_df.dropna()

# Drop duplicate rows
jobs_df= jobs_df.drop_duplicates()

# Show the cleaned dataset
print(jobs_df.info())

# Create a new column by combining relevant text data
jobs_df['combined_features'] = jobs_df['Industry'] + ' ' + jobs_df['Key Skills'] + ' ' + jobs_df['Functional Area']

# Show the combined features for the first few rows
print(jobs_df['combined_features'].head())

# Initialize the TF-IDF Vectorizer
tfidf = TfidfVectorizer(stop_words='english')

# Fit and transform the combined features into a vector
vector_matrix = tfidf.fit_transform(jobs_df['combined_features'])

# Show the shape of the vectorized data
print(vector_matrix.shape)

# Calculate cosine similarity between jobs
similarity_matrix = cosine_similarity(vector_matrix)

# Show the similarity matrix
print(similarity_matrix)

# !pip install tabulate # Install the necessary package

from tabulate import tabulate # import the 'tabulate' function


def recommend_jobs(user_skills, user_industry, user_functional_area, data, similarity_matrix):
    """
    Recommends jobs based on user preferences: skills, industry, and functional area.
    """

    # Combine user input into a single string
    user_input = f"{user_skills} {user_industry} {user_functional_area}"

    # Vectorize the user input to match it against jobs
    user_vector = tfidf.transform([user_input])

    # Calculate similarity scores between user input and all jobs
    user_similarity_scores = cosine_similarity(user_vector, vector_matrix)

    # Get the top 5 most similar jobs
    sorted_indices = user_similarity_scores[0].argsort()[::-1][:5]

    # Print the recommendations
    print("Recommended Jobs:")

    # Create a list to store recommendations
    recommendations = []


    for idx in sorted_indices:
      recommendations.append({
            'Job Title': data.iloc[idx]['Job Title'],
            'Industry': data.iloc[idx]['Industry'],
            'Functional Area': data.iloc[idx]['Functional Area'],
            'Role': data.iloc[idx]['Role'],  # Assuming 'Role' column exists
            'Similarity_Score': user_similarity_scores[0][idx]

    })

    # Create a DataFrame from the recommendations list
    return pd.DataFrame(recommendations)

    # Get recommendations
recommendations_df = recommend_jobs(user_skills, user_industry, user_functional_area, jobs_df, similarity_matrix)

# Select columns to display
output_columns = ['Job Title', 'Industry', 'Functional Area', 'Role', 'Similarity_Score']
top_recommendations = recommendations_df[output_columns].head(5)

# Convert to table format
print(tabulate(top_recommendations, headers='keys', tablefmt='fancy_grid'))

# Example user input
user_skills = " art"
user_industry = "art"
user_functional_area = "art"

# Test the recommendation function
recommend_jobs(user_skills, user_industry, user_functional_area, jobs_df, similarity_matrix)

from matplotlib import pyplot as plt
import seaborn as sns
import pandas as pd
plt.subplots(figsize=(8, 8))
df_2dhist = pd.DataFrame({
    x_label: grp['Functional Area'].value_counts()
    for x_label, grp in _df_14.groupby('Industry')
})
sns.heatmap(df_2dhist, cmap='viridis')
plt.xlabel('Industry')
_ = plt.ylabel('Functional Area')